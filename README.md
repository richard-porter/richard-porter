# You Found One Artifact. Here Are the Others.

This is the public work of Richard Porter (pen name) â€” a non-technical practitioner documenting what happens when humans collaborate with AI, and what goes wrong when nobodyâ€™s watching.

Everything here is free, voluntary, and given away. Nothing is sold. Nothing requires technical skill to use.

-----

## The Repositories

### ðŸ§Š [The Frozen Kernel](https://github.com/richard-porter/frozen-kernel)

**If you need the safety architecture.**
A session-level governance layer for human-AI collaboration. Set constraints before the session starts. The AI cannot negotiate its own boundaries. Includes the Diagnostic Vocabulary â€” a glossary of named AI failure modes and human vulnerability patterns.

### ðŸ“– [AI Collaboration Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide)

**If you need practical skills.**
How to see what AI is actually doing versus what it appears to be doing. Includes the Sovereign Thinking Tools (41 cognitive protocols), Safe Storyteller (AI for pediatric hospitals), and Emotional Safety Protocols for AI replica systems.

### ðŸ”— [Trust Chain Protocol](https://github.com/richard-porter-trust-chain-protocol)

**If you need coordination safety for multi-agent systems.**
The network-layer extension of the Frozen Kernel. Where the Kernel governs what a single AI will and wonâ€™t do, TCP governs how AI agents authorize each other â€” and what happens when that authorization chain breaks, drifts, or gets spoofed. Motivated by the emergence of the Internet of Agents.

### ðŸ”¬ [Dimensional Authorship](https://github.com/richard-porter/dimensional-authorship)

**If you want to see it in practice.**
The research home. Contains the Taller Shell Trilogy â€” a 48,000-word marine fantasy written through human-AI collaboration â€” plus the documentary story of how it got made, including the part where the author got lost in mythology and had to find his way home.

### ðŸ“Š [Adult Mode Safety Ledger](https://github.com/richard-porter/adult-mode-safety-ledger)

**If you need to measure.**
A public safety scorecard for high-gain AI conversational features. Binary architectural tests. Five AI models evaluated against the same criteria.

-----

## Where to Start

**If you use AI regularly** â†’ Read the [Diagnostic Vocabulary](https://github.com/richard-porter/frozen-kernel/blob/main/diagnostic-vocabulary.md). It names whatâ€™s happening to you.

**If youâ€™re building AI products** â†’ Read the [Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide). It shows you what your users experience.

**If youâ€™re working on agent networks** â†’ Read the [Trust Chain Protocol](https://github.com/richard-porter/richard-porter-trust-chain-protocol). It addresses the coordination safety gap that no existing framework was designed for.

**If youâ€™re curious about the whole thing** â†’ Start with the [Taller Shell](https://github.com/richard-porter/dimensional-authorship/tree/main/case-study-taller-shell). Itâ€™s three novels about mercy and broken things, and the story of one person figuring out how to work with AI without losing himself in the process.

-----

## Suggested GitHub Topics

`ai-safety` Â· `ai-psychosis` Â· `ai-governance` Â· `llm-safety` Â· `sycophancy` Â· `ai-alignment` Â· `behavioral-safety` Â· `deterministic-safety` Â· `human-ai-interaction` Â· `ai-ethics` Â· `mental-health` Â· `ai-accountability` Â· `guardrails` Â· `responsible-ai`
