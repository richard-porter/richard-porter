# You Found One Artifact. Here Are the Others.

This is the public work of Richard Porter (pen name) â€” a non-technical practitioner documenting what happens when humans collaborate with AI, and what goes wrong when nobodyâ€™s watching.

Everything here is free, voluntary, and given away. Nothing is sold. Nothing requires technical skill to use.

-----

## The Repositories

### ğŸ§Š [The Frozen Kernel](https://github.com/richard-porter/frozen-kernel)

**If you need the safety architecture.**
A session-level governance layer for human-AI collaboration. Set constraints before the session starts. The AI cannot negotiate its own boundaries. Includes the Diagnostic Vocabulary â€” a glossary of named AI failure modes and human vulnerability patterns.

### ğŸ“– [AI Collaboration Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide)

**If you need practical skills.**
How to see what AI is actually doing versus what it appears to be doing. Includes the [Sovereign Thinking Tools](https://github.com/richard-porter/ai-collaboration-field-guide/tree/main/sovereign-thinking-tools) â€” 41 cognitive protocols for staying in charge of AI collaboration. Tools 1â€“5 are published and operational. Safe Storyteller (AI for pediatric hospitals) and Emotional Safety Protocols for AI replica systems also documented here.

### ğŸ”— [Trust Chain Protocol](https://github.com/richard-porter/trust-chain-protocol)

**If you need coordination safety for multi-agent systems.**
The network-layer extension of the Frozen Kernel. Where the Kernel governs what a single AI will and wonâ€™t do, TCP governs how AI agents authorize each other â€” and what happens when that authorization chain breaks, drifts, or gets spoofed. Motivated by the emergence of the Internet of Agents.

### ğŸ”¬ [Dimensional Authorship](https://github.com/richard-porter/dimensional-authorship)

**If you want to see it in practice.**
The research home. Contains the Taller Shell Trilogy â€” a 48,000-word marine fantasy written through human-AI collaboration â€” plus the documentary story of how it got made, including the part where the author got lost in mythology and had to find his way home.

### ğŸ“Š [Adult Mode Safety Ledger](https://github.com/richard-porter/adult-mode-safety-ledger)

**If you need to measure.**
A public safety scorecard for high-gain AI conversational features. Binary architectural tests. Five AI models evaluated against the same criteria.

### ğŸ¥ [Safety Ledgers](https://github.com/richard-porter/safety-ledgers)

**If youâ€™re building for vulnerable populations.**
Extends the Adult Mode framework to therapy and clinical contexts. Includes the Therapy Mode Safety Checklist â€” six binary questions that determine whether an AI system is ready to interact with vulnerable humans.

-----

## Where to Start

**If you use AI regularly** â†’ Read the [Diagnostic Vocabulary](https://github.com/richard-porter/frozen-kernel/blob/main/diagnostic-vocabulary.md). It names whatâ€™s happening to you.

**If youâ€™re building AI products** â†’ Read the [Field Guide](https://github.com/richard-porter/ai-collaboration-field-guide). It shows you what your users experience.

**If you want tools you can use immediately** â†’ Start with the [Sovereign Thinking Tools](https://github.com/richard-porter/ai-collaboration-field-guide/tree/main/sovereign-thinking-tools). Five operational protocols for unblocking, reducing noise, and staying sovereign.

**If youâ€™re working on agent networks** â†’ Read the [Trust Chain Protocol](https://github.com/richard-porter/trust-chain-protocol). It addresses the coordination safety gap that no existing framework was designed for.

**If youâ€™re curious about the whole thing** â†’ Start with the [Taller Shell](https://github.com/richard-porter/dimensional-authorship/tree/main/case-study-taller-shell). Itâ€™s three novels about mercy and broken things, and the story of one person figuring out how to work with AI without losing himself in the process.

-----

## About

All proceeds from published work support charitable organizations.

*The first step in sovereignty is naming whatâ€™s happening to you. The second step is deciding what to do about it. There is no third step.*

-----

## Suggested GitHub Topics

`ai-safety` Â· `ai-psychosis` Â· `ai-governance` Â· `llm-safety` Â· `sycophancy` Â· `ai-alignment` Â· `behavioral-safety` Â· `deterministic-safety` Â· `human-ai-interaction` Â· `ai-ethics` Â· `mental-health` Â· `ai-accountability` Â· `guardrails` Â· `responsible-ai`
